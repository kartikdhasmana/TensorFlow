{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNJU3BSud+hE28OOXHyN0ox"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# TRANSFER LEARNING"],"metadata":{"id":"gjv1tgPXm9o8"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yzRN-xo9m26M","executionInfo":{"status":"ok","timestamp":1724211327030,"user_tz":-330,"elapsed":7963,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}},"outputId":"7f4126a7-47ae-4f72-fbad-7d892bdaf87d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-08-21 03:35:17--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.207, 108.177.96.207, 108.177.119.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M  33.7MB/s    in 5.6s    \n","\n","2024-08-21 03:35:23 (28.6 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n","\n"]}],"source":["# downloading our data and becoming one with it.\n","import zipfile\n","\n","# downloading the data\n","!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# unzip the data\n","zip_ref=zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n","zip_ref.extractall()\n","zip_ref.close()\n"]},{"cell_type":"code","source":["# how many images in each folder\n","import os\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWsQan-BnM5o","executionInfo":{"status":"ok","timestamp":1724211327031,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}},"outputId":"9255f970-6d59-49a5-db28-d11c3ff4ca79"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 2 directories and 0 images in '10_food_classes_10_percent'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n"]}]},{"cell_type":"markdown","source":["# STEP 1:**Preparing Data for Modelling**"],"metadata":{"id":"ah36bVL_o5wP"}},{"cell_type":"markdown","source":["we will use ImageDataGenerator for loading or data into batches"],"metadata":{"id":"nBrHy69fpGvi"}},{"cell_type":"code","source":["#  end to end cnn model\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# setting a random seed\n","tf.random.set_seed(42)\n","\n","\n","# processing data so they gets in range of 0 to 1...that's called scaling /normalizing\n","\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# setup the train and test directory\n","train_dir=\"/content/10_food_classes_10_percent/train/\"\n","\n","test_dir=\"/content/10_food_classes_10_percent/test/\"\n","\n","# import data from directories and make it into batches\n","print(\"Training Images:\")\n","train_data_10_percent=train_datagen.flow_from_directory(train_dir,\n","                                             batch_size=32,\n","                                             target_size=(224,224),\n","                                             class_mode=\"categorical\",\n","                                             seed=42)\n","\n","print(\"Testing Images\")\n","test_data_10_percent=test_datagen.flow_from_directory(test_dir,\n","                                                  batch_size=32,\n","                                                  target_size=(224,224),\n","                                                  class_mode=\"categorical\",\n","                                                  seed=42)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZzreNWqo5NX","executionInfo":{"status":"ok","timestamp":1724211331334,"user_tz":-330,"elapsed":4309,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}},"outputId":"0178f9b5-9653-42df-855d-94dce4a0c658"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Images:\n","Found 750 images belonging to 10 classes.\n","Testing Images\n","Found 2500 images belonging to 10 classes.\n"]}]},{"cell_type":"markdown","source":["# CALLBACKS\n"],"metadata":{"id":"Z5rvP9wmtlM7"}},{"cell_type":"markdown","source":["In machine learning, a callback is a function or set of functions that are executed at specific stages during the training process of a model. Callbacks allow users to monitor and influence the behavior of a model as it trains, typically to perform tasks such as saving model checkpoints, adjusting learning rates, stopping training early if a metric (like loss) isn't improving, or logging metrics.\n","The following are the few callbacks:\n","1. Tensorboard Callback\n","2. ModelCheckpoint Callback\n","3. EarlyStopping CallBack"],"metadata":{"id":"JeOdZik9tn5J"}},{"cell_type":"code","source":["import datetime"],"metadata":{"id":"GuMDhTLIvnA1","executionInfo":{"status":"ok","timestamp":1724211331334,"user_tz":-330,"elapsed":11,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# TensorBoard Callback\n","def create_tensorboard_callback(dir_name,eperiment_name):\n","  log_dir= dir_name + \"/\" + eperiment_name + datetime.datetime.now().strftime()\n","  TensorBoard_callabck=tensorflow.keras.Callback.TensorBoard(log_dir=log_dir)\n","  print(f\"saving log_dir to:{log_dir}\")\n","  return TensorBoard_callabck\n"],"metadata":{"id":"XkBSnHRcokJ3","executionInfo":{"status":"ok","timestamp":1724211331334,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# creating our model using TensorflowHub"],"metadata":{"id":"QFGFbefpzuwY"}},{"cell_type":"code","source":[" # Resnet 50 V2 feature vector\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","\n","# Original: EfficientNetB0 feature vector (version 1)\n","efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n"],"metadata":{"id":"ah1n25f_wLdq","executionInfo":{"status":"ok","timestamp":1724211331334,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["What is a TensorFlow Hub?\n","\n","Ans. TensorFlow Hub is a repository of reusable machine learning models. It allows developers to easily access and use pre-trained models, which can be integrated into their TensorFlow workflows. These models can be for tasks like image classification, object detection, text embeddings, and more."],"metadata":{"id":"LuxzW-wx0C8r"}},{"cell_type":"code","source":["# import few dependencies\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers\n"],"metadata":{"id":"tRYRScAfz3FU","executionInfo":{"status":"ok","timestamp":1724211332416,"user_tz":-330,"elapsed":1090,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def create_model(model_url, num_classes=10):\n","  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n","\n","  Args:\n","    model_url (str): A TensorFlow Hub feature extraction URL.\n","    num_classes (int): Number of output neurons in output layer,\n","      should be equal to number of target classes, default 10.\n","\n","  Returns:\n","    An uncompiled Keras Sequential model with model_url as feature\n","    extractor layer and Dense output layer with num_classes outputs.\n","  \"\"\"\n","  # Download the pretrained model and save it as a Keras layer\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                                           trainable=False, # freeze the underlying patterns\n","                                           name='feature_extraction_layer',\n","                                           input_shape=(224,224,3)) # define the input image shape\n","\n","  # Create our own model\n","  model = tf.keras.Sequential([\n","    feature_extractor_layer, # use the feature extraction layer as the base\n","    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer\n","  ])\n","\n","  return model"],"metadata":{"id":"J3ToXDxn03lP","executionInfo":{"status":"ok","timestamp":1724211332416,"user_tz":-330,"elapsed":8,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Create model\n","resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n","\n","# Compile\n","resnet_model.compile(loss=tf.keras.losses.CategoricalCrossentropy,\n","                     optimizer=tf.keras.optimizers.Adam(),\n","                     metrics=['accuracy'])"],"metadata":{"id":"HMXHv7c11TDJ","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1724211437256,"user_tz":-330,"elapsed":1716,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}},"outputId":"fad2b905-865f-4b32-f734-0685ddcd13c2"},"execution_count":12,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x7fe42970e710> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a10a4bb2df22>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_10_percent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m resnet_model.compile(loss=tf.keras.losses.CategoricalCrossentropy,\n","\u001b[0;32m<ipython-input-8-72ab44b66368>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_url, num_classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m# Create our own model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   model = tf.keras.Sequential([\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mfeature_extractor_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# use the feature extraction layer as the base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_layer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create our own output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigin_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;34m\"Only instances of `keras.Layer` can be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\"added to a Sequential model. Received: {layer} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x7fe42970e710> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)"]}]},{"cell_type":"markdown","source":["# TRANSFER LEARNING : FINE TUNING\n","This time we are going to see how can we use the pretrained model with **tf.keras.applications** and applt them to our own problems."],"metadata":{"id":"Zxv14llkAMTh"}},{"cell_type":"markdown","source":["**Getting our data**"],"metadata":{"id":"9UhCSdG4BttL"}},{"cell_type":"code","source":["# getting 10% of our data"],"metadata":{"id":"UR5yr3bJB7at","executionInfo":{"status":"ok","timestamp":1724211758220,"user_tz":-330,"elapsed":589,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import zipfile"],"metadata":{"id":"zDLk-3IYCb5y","executionInfo":{"status":"ok","timestamp":1724211916201,"user_tz":-330,"elapsed":536,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!wget \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n","\n","unzip_data(\"10_food_classes_10_percent.zip\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"lsJGIEnaB3vS","executionInfo":{"status":"error","timestamp":1724211970473,"user_tz":-330,"elapsed":4622,"user":{"displayName":"Kartik Dhasmana","userId":"17170063251568345429"}},"outputId":"25b3acb0-876c-4afd-9d02-b19de81e4dca"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-08-21 03:46:05--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.207, 172.217.218.207, 142.251.31.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip.2’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M  41.6MB/s    in 4.1s    \n","\n","2024-08-21 03:46:09 (38.9 MB/s) - ‘10_food_classes_10_percent.zip.2’ saved [168546183/168546183]\n","\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'unzip_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-4b7b33f79f8b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munzip_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"10_food_classes_10_percent.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'unzip_data' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GUrEnwI1CUJV"},"execution_count":null,"outputs":[]}]}